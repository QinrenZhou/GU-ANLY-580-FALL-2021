{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03: Text Classification on the DBpedia14 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives:\n",
    "1. Build a Naive Bayes classification model from scratch\n",
    "2. Evaluate the performance of your model on the DBpedia14 dataset\n",
    "3. Train an off-the-shelf NB classifier and compare its performance to your implementation\n",
    "4. Train off-the-shelf implementations of the linear-SVM, RBF-kernel-SVM, and perceptron and compare their performance with the NB models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested Reading\n",
    "\n",
    "1. https://arxiv.org/pdf/1811.12808.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset d_bpedia14 (C:\\Users\\Administrator\\.cache\\huggingface\\datasets\\d_bpedia14\\dbpedia_14\\2.0.0\\7f0577ea0f4397b6b89bfe5c5f2c6b1b420990a1fc5e8538c7ab4ec40e46fa3e)\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "train_ds, test_ds = datasets.load_dataset('dbpedia_14', split=['train[:80%]', 'test[80%:]'])\n",
    "df_train: pd.DataFrame = train_ds.to_pandas()\n",
    "df_test: pd.DataFrame = test_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448000, 14000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train),len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>E. D. Abbott Ltd</td>\n",
       "      <td>Abbott of Farnham E D Abbott Limited was a Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Schwan-Stabilo</td>\n",
       "      <td>Schwan-STABILO is a German maker of pens for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Q-workshop</td>\n",
       "      <td>Q-workshop is a Polish company located in Poz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Marvell Software Solutions Israel</td>\n",
       "      <td>Marvell Software Solutions Israel known as RA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Bergan Mercy Medical Center</td>\n",
       "      <td>Bergan Mercy Medical Center is a hospital loc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                              title  \\\n",
       "0      0                   E. D. Abbott Ltd   \n",
       "1      0                     Schwan-Stabilo   \n",
       "2      0                         Q-workshop   \n",
       "3      0  Marvell Software Solutions Israel   \n",
       "4      0        Bergan Mercy Medical Center   \n",
       "\n",
       "                                             content  \n",
       "0   Abbott of Farnham E D Abbott Limited was a Br...  \n",
       "1   Schwan-STABILO is a German maker of pens for ...  \n",
       "2   Q-workshop is a Polish company located in Poz...  \n",
       "3   Marvell Software Solutions Israel known as RA...  \n",
       "4   Bergan Mercy Medical Center is a hospital loc...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Thunes Mekaniske Værksted A/S Thune for short was a Norwegian manufacturing company that among other things built locomotives. The production facilities were last located at Skøyen.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"content\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 448000 entries, 0 to 447999\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   label    448000 non-null  int64 \n",
      " 1   title    448000 non-null  object\n",
      " 2   content  448000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 10.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = df_train[\"label\"]\n",
    "max(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>448000</td>\n",
       "      <td>448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>448000</td>\n",
       "      <td>447896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Protea neriifolia</td>\n",
       "      <td>Steinkopf is a mountain of Hesse Germany.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title                                     content\n",
       "count              448000                                      448000\n",
       "unique             448000                                      447896\n",
       "top     Protea neriifolia   Steinkopf is a mountain of Hesse Germany.\n",
       "freq                    1                                           4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*note: the dataset is so large that it consume much time ,here I select first 10000 instances as sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "new_doc=[]\n",
    "new_label=[]\n",
    "index=random.sample(range(0,len(df_train)),10000)\n",
    "for i in index:\n",
    "    new_doc.append(df_train[\"content\"][i])\n",
    "    new_label.append(df_train[\"label\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({'content':new_doc,'label':new_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize_document(doc):\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    \n",
    "    # tokenize document\n",
    "    word_tokens = word_tokenize(doc)   \n",
    "    # filter stopwords out of document\n",
    "    filtered_sentence = [] \n",
    "    for w in word_tokens: \n",
    "        if w not in stopwords: \n",
    "            filtered_sentence.append(w) \n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_sentence)\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize document\n",
    "norm_doc = new_df['content'].apply(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rivka galchen born april canadianamerican writer first novel atmospheric disturbances published translated languages awarded william saroyan international prize writing'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    rivka galchen born april canadianamerican writ...\n",
       "1    taxonomy triploceras genus algae specifically ...\n",
       "2    scopula pseudocorrivalaria moth geometridae fa...\n",
       "3    hayward high school hhs serves students around...\n",
       "4    fleur pellerin french pronunciation fl pl born...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "#initialze lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize document\n",
    "lemm_doc= norm_doc.apply(lemmatize_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rivka galchen bear april canadianamerican writer first novel atmospheric disturbance publish translated language award william saroyan international prize writing'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    rivka galchen bear april canadianamerican writ...\n",
       "1    taxonomy triploceras genus algae specifically ...\n",
       "2    scopula pseudocorrivalaria moth geometridae fa...\n",
       "3    hayward high school hhs serve student around h...\n",
       "4    fleur pellerin french pronunciation fl pl bear...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm_doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert normalized, lemmatized text to numeric format\n",
    "cv = CountVectorizer()\n",
    "cv_df = cv.fit_transform(lemm_doc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert normalized, lemmatized text to numeric format\n",
    "tdif = TfidfVectorizer()\n",
    "tdif_df =  tdif.fit_transform(lemm_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = tdif_df\n",
    "y_data = new_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_data, y_data, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 43775)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part I: Build your own Naive Bayes classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5 pts) Task I: Build a model from scratch\n",
    "Using your notes from lecture-02, implement a Naive Bayes model and train it on the DBpedia dataset. Also, feel free to use any text preprocessing you wish, such as the pipeline from Lab02. \n",
    "\n",
    "Below is a template class to help you think about the structure of this problem (feel free to design your own code if you like). It contains methods for each inference step in NB. It also has a classmethod that you could use to instantiate the class from a list of documents and a corresponding list of labels. Here we are suggesting you create a dictionary that maps each word to a unique $ith$ index in the $\\phi_{i,k}$ probabilty matrix, which you need to estimate. Because the labels are a set of 0-indexed integers, they naturally map to a unique position $\\mu_{k}$ (you should check this to make sure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesModel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dictionary = {}\n",
    "        self.classes = None\n",
    "    \n",
    "    def fit(self,x_train,y_train):\n",
    "        x_train = x_train.toarray()\n",
    "        self.classes=set(y_train)\n",
    "        self.dictionary[\"total_y\"]=y_train.shape[0]\n",
    "    \n",
    "        for current_class in self.classes:\n",
    "            self.dictionary[current_class]={}\n",
    "        \n",
    "            # dataset selection for a particular class\n",
    "            criteria=(y_train == current_class)\n",
    "            x_train_current=x_train[criteria]\n",
    "            y_train_current=y_train[criteria]\n",
    "        \n",
    "            self.dictionary[current_class][\"total_word_count_in_class\"]=sum(map(sum,x_train_current))\n",
    "            self.dictionary[current_class][\"total_y_in_class\"]=y_train_current.shape[0]\n",
    "             \n",
    "            num_features=x_train.shape[-1]\n",
    "            for i in range(1,num_features+1):\n",
    "                self.dictionary[current_class][i]=sum(x_train_current[:,i-1])\n",
    "    \n",
    "    def probability(self,x,current_class):      \n",
    "        output=np.log(self.dictionary[current_class][\"total_y_in_class\"]) - np.log(self.dictionary[\"total_y\"])\n",
    "        num_features=len(self.dictionary[current_class].keys()) - 2\n",
    "        for i in range(1,num_features + 1):\n",
    "            count_current_class_with_feature_word=self.dictionary[current_class][i] + 1\n",
    "            count_current_class_with_all_feature_words=self.dictionary[current_class][\"total_word_count_in_class\"]+num_features\n",
    "        \n",
    "            probability_of_feature_word=np.log(count_current_class_with_feature_word) - np.log(count_current_class_with_all_feature_words)\n",
    "            x_copy=x.copy()\n",
    "            while x_copy[i-1]>0:\n",
    "                output+=probability_of_feature_word\n",
    "                x_copy[i-1]-=1\n",
    "        return output\n",
    "        \n",
    "    def _predict(self,x):       \n",
    "        best_class=-1000\n",
    "        best_p=1000\n",
    "        first_run=True  \n",
    "        # storing all the classes in class_values\n",
    "        class_values=self.dictionary.keys()\n",
    "    \n",
    "        # loops over ALL THE CLASSES\n",
    "        for current_class in class_values:\n",
    "            if current_class==\"total_y\":\n",
    "                continue\n",
    "            \n",
    "            # calculate probability corresponding to every class\n",
    "            current_class_p=self.probability(x,current_class)\n",
    "        \n",
    "            # calculating best probability and class\n",
    "            if first_run or best_p < current_class_p:\n",
    "                best_p=current_class_p\n",
    "                best_class=current_class\n",
    "            first_run=False\n",
    "        return best_class\n",
    "\n",
    "    def predict(self,x_test):\n",
    "        x_test = x_test.toarray()\n",
    "        y_pred = [] \n",
    "        for index in range(x_test.shape[0]):\n",
    "            y_pred.append(self._predict(x_test[index]))    \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "Bayes = NaiveBayesModel()\n",
    "Bayes.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Bayes.predict(x_test[:100,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Model performance evaluation\n",
    "\n",
    "Evaluating the performance of a classification model may seem as simple as computing an accuracy, and in some cases that is sufficient, but in general accuracy is not a reliable metric by itself. Typically we need to evaluate our model using several different metrics. \n",
    "\n",
    "One common issue is class imbalance, which is when the label distribution in the data varies far from uniform. In this case a high accuracy can be misleading because low frequency labels don't contribute equally to the score. More generally, this is one of the biggest drawbacks of using MLE in NLP: models tend to be much less sensitive to low probability labels than to higher probabilty labels. Later in this class we will explore models that learn by predicting words given their context, can you think of reasons why this can be problematic? Hint: remember Zipf's law?\n",
    "\n",
    "Another reason to use multiple evaluation methods is that it can help you better understand your data. Evaluating performance on individual classes often reveals problems with the data that would otherwise go unnoticed. For example, if you observe an abundance of misclassified data specific to only a few classes, chances are you have inconsistent labels for those classes in the training set. This is very common in 3rd party mechanical turk data, where quality can vary wildly.\n",
    "\n",
    "In this lab we will use three metrics and one visualization tool:\n",
    "\n",
    "1. [Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision)\n",
    "2. [F1 score](https://en.wikipedia.org/wiki/F-score)\n",
    "3. [AUC ROC score](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n",
    "4. [The confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)\n",
    "\n",
    "The [metrics module](https://scikit-learn.org/stable/modules/model_evaluation.html) within sklearn provides support for nearly any evaluation metric that you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n",
      "0.92\n",
      "[[ 7  0  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  8  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 12  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  6  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  6  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  7  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  9  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1 11  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  5  1  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  8  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test[:100],y_pred))\n",
    "print(f1_score(y_test[:100],y_pred,average='micro'))\n",
    "print(confusion_matrix(y_test[:100],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Compare your performance to an off-the-shelf NB classifier\n",
    "Open source implementations of your custom NB classifier from Part I already exist of course. One such implementation is [`sklearn.naive_bayes.MultinomialNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) from the sklearn library. \n",
    "\n",
    "### (5 pts) Task II: NB model comparison\n",
    "Train this model on the same data and compare its performance with your model using the metrics from part II."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "mnb = MultinomialNB().fit(x_train, y_train)\n",
    "y_pred = mnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9292\n",
      "0.9292\n",
      "[[218   3  12   0   1  12   3   0   0   0   0   0]\n",
      " [  3 216   0   0   0   1   3   1   0   0   0   0]\n",
      " [  3   2 201   2   8   1   2   0   0   0   0   0]\n",
      " [  0   0   4 200   3   2   0   0   0   0   0   0]\n",
      " [  2   2   0   2 211   1   1   0   0   0   0   0]\n",
      " [  5   0   0   0   0 221   1   0   0   0   0   0]\n",
      " [  4   6   2   0   1   1 196   3   0   0   0   0]\n",
      " [  0   0   0   0   0   1   1 225   0   0   1   0]\n",
      " [  0   0   0   0   1   1   5   2 238   0   0   0]\n",
      " [  0   0   0   2   0   0   0   0   0 201  12   0]\n",
      " [  1   0   0   0   0   1   0   0   0   2 196   0]\n",
      " [  0   0  50   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n",
    "print(f1_score(y_test,y_pred,average='micro'))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV: Compare NB to other classification models\n",
    "\n",
    "Now that we've built and validated our NB classifier, we want to evaluate other models on this task.\n",
    "\n",
    "### (5 pts) Task III: Evaluate the perceptron, SVM (linear), and SVM (RBF kernel)\n",
    "Train and evaluate the following models on this dataset, and compare them with the NB models.\n",
    "\n",
    "1. [Perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html#sklearn.linear_model.Perceptron)\n",
    "2. [Linear-SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html)\n",
    "3. [RBF-Kernel-SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "per = Perceptron().fit(x_train,y_train)\n",
    "y_pred = per.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9504\n",
      "0.9504\n",
      "[[225   3  11   0   0   6   3   0   0   1   0   0]\n",
      " [  4 215   0   0   1   1   1   0   0   2   0   0]\n",
      " [  6   3 197   2   5   0   1   0   0   2   0   3]\n",
      " [  0   0   4 198   6   0   0   0   0   0   0   1]\n",
      " [  1   2   0   0 212   2   1   0   0   0   0   1]\n",
      " [  6   0   0   0   0 219   2   0   0   0   0   0]\n",
      " [  6   5   3   1   2   1 191   2   1   0   1   0]\n",
      " [  0   0   0   0   0   2   1 224   0   1   0   0]\n",
      " [  0   0   0   0   0   0   2   2 243   0   0   0]\n",
      " [  1   0   0   0   1   0   0   0   0 209   4   0]\n",
      " [  0   1   0   0   0   0   0   0   0   2 197   0]\n",
      " [  1   0   3   0   0   0   0   0   0   0   0  46]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n",
    "print(f1_score(y_test,y_pred,average='micro'))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(x_train,y_train)\n",
    "y_pred = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9436\n",
      "0.9436\n",
      "[[234   1   7   0   0   5   2   0   0   0   0   0]\n",
      " [  5 212   3   0   0   0   4   0   0   0   0   0]\n",
      " [  5   2 207   0   3   0   0   0   0   0   0   2]\n",
      " [  0   0  12 192   3   2   0   0   0   0   0   0]\n",
      " [  3   2   4   0 208   1   1   0   0   0   0   0]\n",
      " [  8   0   0   0   1 217   1   0   0   0   0   0]\n",
      " [  6   3   5   0   0   0 197   2   0   0   0   0]\n",
      " [  2   0   0   0   1   1   1 223   0   0   0   0]\n",
      " [  4   0   1   0   0   0   2   1 239   0   0   0]\n",
      " [  1   0   1   0   0   0   0   0   0 210   3   0]\n",
      " [  3   0   1   0   0   1   0   0   0  10 185   0]\n",
      " [  1   0  14   0   0   0   0   0   0   0   0  35]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n",
    "print(f1_score(y_test,y_pred,average='micro'))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcLinear = LinearSVC()\n",
    "svcLinear.fit(x_train,y_train)\n",
    "y_pred = svcLinear.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.962\n",
      "0.962\n",
      "[[231   1   7   0   0   7   3   0   0   0   0   0]\n",
      " [  5 218   0   0   0   0   1   0   0   0   0   0]\n",
      " [  5   1 204   0   6   0   0   0   0   1   0   2]\n",
      " [  1   0   4 197   4   2   0   0   0   0   0   1]\n",
      " [  3   2   1   0 211   1   1   0   0   0   0   0]\n",
      " [  6   0   0   0   1 218   1   1   0   0   0   0]\n",
      " [  4   4   2   0   0   0 198   3   2   0   0   0]\n",
      " [  0   0   0   0   1   1   1 225   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   2 245   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 212   3   0]\n",
      " [  0   0   0   0   0   1   0   0   0   2 197   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0  49]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n",
    "print(f1_score(y_test,y_pred,average='micro'))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5 pts) Task IV: Select the best model\n",
    "\n",
    "1. Which model performed the best overall? \n",
    "2. What metric(s) influence this decision?\n",
    "3. Does the model that learns a non-linear decision boundary help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the results above ,best model is LinearSVC. It is helpful to learn the model of nonlinear decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
